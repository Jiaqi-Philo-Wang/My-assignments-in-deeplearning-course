{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "电商18 180412126 王佳琦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.240\n",
      "[1,  4000] loss: 1.920\n",
      "[1,  6000] loss: 1.697\n",
      "[1,  8000] loss: 1.623\n",
      "[1, 10000] loss: 1.546\n",
      "[1, 12000] loss: 1.465\n",
      "Accuracy of the network on the 2500 test images: 44 %\n",
      "[1] loss: 1.511\n",
      "12499\n",
      "[2,  2000] loss: 1.421\n",
      "[2,  4000] loss: 1.363\n",
      "[2,  6000] loss: 1.332\n",
      "[2,  8000] loss: 1.320\n",
      "[2, 10000] loss: 1.283\n",
      "[2, 12000] loss: 1.270\n",
      "Accuracy of the network on the 2500 test images: 54 %\n",
      "[2] loss: 1.320\n",
      "12499\n",
      "[3,  2000] loss: 1.211\n",
      "[3,  4000] loss: 1.190\n",
      "[3,  6000] loss: 1.182\n",
      "[3,  8000] loss: 1.170\n",
      "[3, 10000] loss: 1.172\n",
      "[3, 12000] loss: 1.159\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[3] loss: 1.192\n",
      "12499\n",
      "[4,  2000] loss: 1.085\n",
      "[4,  4000] loss: 1.080\n",
      "[4,  6000] loss: 1.101\n",
      "[4,  8000] loss: 1.080\n",
      "[4, 10000] loss: 1.097\n",
      "[4, 12000] loss: 1.067\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[4] loss: 1.132\n",
      "12499\n",
      "[5,  2000] loss: 0.993\n",
      "[5,  4000] loss: 1.006\n",
      "[5,  6000] loss: 1.018\n",
      "[5,  8000] loss: 1.000\n",
      "[5, 10000] loss: 1.020\n",
      "[5, 12000] loss: 1.013\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[5] loss: 1.096\n",
      "12499\n",
      "[6,  2000] loss: 0.928\n",
      "[6,  4000] loss: 0.937\n",
      "[6,  6000] loss: 0.958\n",
      "[6,  8000] loss: 0.963\n",
      "[6, 10000] loss: 0.964\n",
      "[6, 12000] loss: 0.969\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[6] loss: 1.083\n",
      "12499\n",
      "[7,  2000] loss: 0.876\n",
      "[7,  4000] loss: 0.901\n",
      "[7,  6000] loss: 0.891\n",
      "[7,  8000] loss: 0.913\n",
      "[7, 10000] loss: 0.935\n",
      "[7, 12000] loss: 0.930\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[7] loss: 1.134\n",
      "12499\n",
      "[8,  2000] loss: 0.818\n",
      "[8,  4000] loss: 0.859\n",
      "[8,  6000] loss: 0.871\n",
      "[8,  8000] loss: 0.877\n",
      "[8, 10000] loss: 0.897\n",
      "[8, 12000] loss: 0.903\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[8] loss: 1.112\n",
      "12499\n",
      "[9,  2000] loss: 0.780\n",
      "[9,  4000] loss: 0.811\n",
      "[9,  6000] loss: 0.844\n",
      "[9,  8000] loss: 0.858\n",
      "[9, 10000] loss: 0.861\n",
      "[9, 12000] loss: 0.845\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[9] loss: 1.130\n",
      "12499\n",
      "[10,  2000] loss: 0.764\n",
      "[10,  4000] loss: 0.767\n",
      "[10,  6000] loss: 0.808\n",
      "[10,  8000] loss: 0.802\n",
      "[10, 10000] loss: 0.837\n",
      "[10, 12000] loss: 0.828\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[10] loss: 1.115\n",
      "12499\n",
      "[11,  2000] loss: 0.720\n",
      "[11,  4000] loss: 0.739\n",
      "[11,  6000] loss: 0.774\n",
      "[11,  8000] loss: 0.787\n",
      "[11, 10000] loss: 0.792\n",
      "[11, 12000] loss: 0.826\n",
      "Accuracy of the network on the 2500 test images: 64 %\n",
      "[11] loss: 1.089\n",
      "12499\n",
      "[12,  2000] loss: 0.691\n",
      "[12,  4000] loss: 0.726\n",
      "[12,  6000] loss: 0.776\n",
      "[12,  8000] loss: 0.771\n",
      "[12, 10000] loss: 0.775\n",
      "[12, 12000] loss: 0.771\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[12] loss: 1.147\n",
      "12499\n",
      "[13,  2000] loss: 0.671\n",
      "[13,  4000] loss: 0.724\n",
      "[13,  6000] loss: 0.736\n",
      "[13,  8000] loss: 0.734\n",
      "[13, 10000] loss: 0.753\n",
      "[13, 12000] loss: 0.775\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[13] loss: 1.273\n",
      "12499\n",
      "[14,  2000] loss: 0.664\n",
      "[14,  4000] loss: 0.697\n",
      "[14,  6000] loss: 0.703\n",
      "[14,  8000] loss: 0.718\n",
      "[14, 10000] loss: 0.740\n",
      "[14, 12000] loss: 0.746\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[14] loss: 1.166\n",
      "12499\n",
      "[15,  2000] loss: 0.630\n",
      "[15,  4000] loss: 0.679\n",
      "[15,  6000] loss: 0.700\n",
      "[15,  8000] loss: 0.713\n",
      "[15, 10000] loss: 0.739\n",
      "[15, 12000] loss: 0.734\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[15] loss: 1.230\n",
      "12499\n",
      "[16,  2000] loss: 0.645\n",
      "[16,  4000] loss: 0.667\n",
      "[16,  6000] loss: 0.688\n",
      "[16,  8000] loss: 0.703\n",
      "[16, 10000] loss: 0.692\n",
      "[16, 12000] loss: 0.743\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[16] loss: 1.310\n",
      "12499\n",
      "[17,  2000] loss: 0.618\n",
      "[17,  4000] loss: 0.658\n",
      "[17,  6000] loss: 0.670\n",
      "[17,  8000] loss: 0.688\n",
      "[17, 10000] loss: 0.696\n",
      "[17, 12000] loss: 0.706\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[17] loss: 1.360\n",
      "12499\n",
      "[18,  2000] loss: 0.601\n",
      "[18,  4000] loss: 0.642\n",
      "[18,  6000] loss: 0.673\n",
      "[18,  8000] loss: 0.650\n",
      "[18, 10000] loss: 0.686\n",
      "[18, 12000] loss: 0.697\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[18] loss: 1.330\n",
      "12499\n",
      "[19,  2000] loss: 0.578\n",
      "[19,  4000] loss: 0.627\n",
      "[19,  6000] loss: 0.643\n",
      "[19,  8000] loss: 0.668\n",
      "[19, 10000] loss: 0.676\n",
      "[19, 12000] loss: 0.686\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[19] loss: 1.378\n",
      "12499\n",
      "[20,  2000] loss: 0.568\n",
      "[20,  4000] loss: 0.596\n",
      "[20,  6000] loss: 0.640\n",
      "[20,  8000] loss: 0.669\n",
      "[20, 10000] loss: 0.688\n",
      "[20, 12000] loss: 0.684\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[20] loss: 1.369\n",
      "12499\n",
      "[21,  2000] loss: 0.571\n",
      "[21,  4000] loss: 0.589\n",
      "[21,  6000] loss: 0.617\n",
      "[21,  8000] loss: 0.644\n",
      "[21, 10000] loss: 0.667\n",
      "[21, 12000] loss: 0.670\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[21] loss: 1.369\n",
      "12499\n",
      "[22,  2000] loss: 0.543\n",
      "[22,  4000] loss: 0.586\n",
      "[22,  6000] loss: 0.655\n",
      "[22,  8000] loss: 0.621\n",
      "[22, 10000] loss: 0.673\n",
      "[22, 12000] loss: 0.664\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[22] loss: 1.406\n",
      "12499\n",
      "[23,  2000] loss: 0.558\n",
      "[23,  4000] loss: 0.593\n",
      "[23,  6000] loss: 0.610\n",
      "[23,  8000] loss: 0.643\n",
      "[23, 10000] loss: 0.664\n",
      "[23, 12000] loss: 0.656\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[23] loss: 1.445\n",
      "12499\n",
      "[24,  2000] loss: 0.535\n",
      "[24,  4000] loss: 0.561\n",
      "[24,  6000] loss: 0.595\n",
      "[24,  8000] loss: 0.635\n",
      "[24, 10000] loss: 0.632\n",
      "[24, 12000] loss: 0.645\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[24] loss: 1.385\n",
      "12499\n",
      "[25,  2000] loss: 0.537\n",
      "[25,  4000] loss: 0.578\n",
      "[25,  6000] loss: 0.609\n",
      "[25,  8000] loss: 0.619\n",
      "[25, 10000] loss: 0.619\n",
      "[25, 12000] loss: 0.633\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[25] loss: 1.495\n",
      "12499\n",
      "[26,  2000] loss: 0.534\n",
      "[26,  4000] loss: 0.582\n",
      "[26,  6000] loss: 0.578\n",
      "[26,  8000] loss: 0.607\n",
      "[26, 10000] loss: 0.619\n",
      "[26, 12000] loss: 0.637\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[26] loss: 1.455\n",
      "12499\n",
      "[27,  2000] loss: 0.541\n",
      "[27,  4000] loss: 0.543\n",
      "[27,  6000] loss: 0.613\n",
      "[27,  8000] loss: 0.593\n",
      "[27, 10000] loss: 0.635\n",
      "[27, 12000] loss: 0.650\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[27] loss: 1.557\n",
      "12499\n",
      "[28,  2000] loss: 0.553\n",
      "[28,  4000] loss: 0.574\n",
      "[28,  6000] loss: 0.586\n",
      "[28,  8000] loss: 0.598\n",
      "[28, 10000] loss: 0.600\n",
      "[28, 12000] loss: 0.639\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[28] loss: 1.620\n",
      "12499\n",
      "[29,  2000] loss: 0.524\n",
      "[29,  4000] loss: 0.582\n",
      "[29,  6000] loss: 0.556\n",
      "[29,  8000] loss: 0.605\n",
      "[29, 10000] loss: 0.619\n",
      "[29, 12000] loss: 0.624\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[29] loss: 1.543\n",
      "12499\n",
      "[30,  2000] loss: 0.514\n",
      "[30,  4000] loss: 0.555\n",
      "[30,  6000] loss: 0.598\n",
      "[30,  8000] loss: 0.591\n",
      "[30, 10000] loss: 0.620\n",
      "[30, 12000] loss: 0.635\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[30] loss: 1.533\n",
      "12499\n",
      "[31,  2000] loss: 0.512\n",
      "[31,  4000] loss: 0.558\n",
      "[31,  6000] loss: 0.575\n",
      "[31,  8000] loss: 0.604\n",
      "[31, 10000] loss: 0.634\n",
      "[31, 12000] loss: 0.633\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[31] loss: 1.694\n",
      "12499\n",
      "[32,  2000] loss: 0.503\n",
      "[32,  4000] loss: 0.579\n",
      "[32,  6000] loss: 0.578\n",
      "[32,  8000] loss: 0.605\n",
      "[32, 10000] loss: 0.613\n",
      "[32, 12000] loss: 0.639\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[32] loss: 1.591\n",
      "12499\n",
      "[33,  2000] loss: 0.504\n",
      "[33,  4000] loss: 0.552\n",
      "[33,  6000] loss: 0.558\n",
      "[33,  8000] loss: 0.577\n",
      "[33, 10000] loss: 0.593\n",
      "[33, 12000] loss: 0.613\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[33] loss: 1.723\n",
      "12499\n",
      "[34,  2000] loss: 0.507\n",
      "[34,  4000] loss: 0.566\n",
      "[34,  6000] loss: 0.577\n",
      "[34,  8000] loss: 0.581\n",
      "[34, 10000] loss: 0.635\n",
      "[34, 12000] loss: 0.633\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[34] loss: 1.671\n",
      "12499\n",
      "[35,  2000] loss: 0.516\n",
      "[35,  4000] loss: 0.563\n",
      "[35,  6000] loss: 0.610\n",
      "[35,  8000] loss: 0.614\n",
      "[35, 10000] loss: 0.600\n",
      "[35, 12000] loss: 0.600\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[35] loss: 1.668\n",
      "12499\n",
      "[36,  2000] loss: 0.512\n",
      "[36,  4000] loss: 0.536\n",
      "[36,  6000] loss: 0.583\n",
      "[36,  8000] loss: 0.604\n",
      "[36, 10000] loss: 0.601\n",
      "[36, 12000] loss: 0.637\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[36] loss: 1.634\n",
      "12499\n",
      "[37,  2000] loss: 0.509\n",
      "[37,  4000] loss: 0.557\n",
      "[37,  6000] loss: 0.593\n",
      "[37,  8000] loss: 0.580\n",
      "[37, 10000] loss: 0.617\n",
      "[37, 12000] loss: 0.614\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[37] loss: 1.857\n",
      "12499\n",
      "[38,  2000] loss: 0.513\n",
      "[38,  4000] loss: 0.558\n",
      "[38,  6000] loss: 0.557\n",
      "[38,  8000] loss: 0.595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 10000] loss: 0.616\n",
      "[38, 12000] loss: 0.656\n",
      "Accuracy of the network on the 2500 test images: 57 %\n",
      "[38] loss: 1.711\n",
      "12499\n",
      "[39,  2000] loss: 0.520\n",
      "[39,  4000] loss: 0.547\n",
      "[39,  6000] loss: 0.586\n",
      "[39,  8000] loss: 0.616\n",
      "[39, 10000] loss: 0.589\n",
      "[39, 12000] loss: 0.623\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[39] loss: 1.730\n",
      "12499\n",
      "[40,  2000] loss: 0.473\n",
      "[40,  4000] loss: 0.514\n",
      "[40,  6000] loss: 0.578\n",
      "[40,  8000] loss: 0.602\n",
      "[40, 10000] loss: 0.602\n",
      "[40, 12000] loss: 0.594\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[40] loss: 1.736\n",
      "12499\n",
      "[41,  2000] loss: 0.495\n",
      "[41,  4000] loss: 0.521\n",
      "[41,  6000] loss: 0.545\n",
      "[41,  8000] loss: 0.614\n",
      "[41, 10000] loss: 0.596\n",
      "[41, 12000] loss: 0.625\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[41] loss: 1.639\n",
      "12499\n",
      "[42,  2000] loss: 0.494\n",
      "[42,  4000] loss: 0.538\n",
      "[42,  6000] loss: 0.590\n",
      "[42,  8000] loss: 0.614\n",
      "[42, 10000] loss: 0.599\n",
      "[42, 12000] loss: 0.609\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[42] loss: 1.790\n",
      "12499\n",
      "[43,  2000] loss: 0.497\n",
      "[43,  4000] loss: 0.530\n",
      "[43,  6000] loss: 0.586\n",
      "[43,  8000] loss: 0.586\n",
      "[43, 10000] loss: 0.580\n",
      "[43, 12000] loss: 0.617\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[43] loss: 1.802\n",
      "12499\n",
      "[44,  2000] loss: 0.536\n",
      "[44,  4000] loss: 0.534\n",
      "[44,  6000] loss: 0.557\n",
      "[44,  8000] loss: 0.584\n",
      "[44, 10000] loss: 0.591\n",
      "[44, 12000] loss: 0.609\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[44] loss: 1.836\n",
      "12499\n",
      "[45,  2000] loss: 0.523\n",
      "[45,  4000] loss: 0.566\n",
      "[45,  6000] loss: 0.560\n",
      "[45,  8000] loss: 0.574\n",
      "[45, 10000] loss: 0.626\n",
      "[45, 12000] loss: 0.606\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[45] loss: 1.920\n",
      "12499\n",
      "[46,  2000] loss: 0.524\n",
      "[46,  4000] loss: 0.503\n",
      "[46,  6000] loss: 0.585\n",
      "[46,  8000] loss: 0.583\n",
      "[46, 10000] loss: 0.618\n",
      "[46, 12000] loss: 0.613\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[46] loss: 1.885\n",
      "12499\n",
      "[47,  2000] loss: 0.520\n",
      "[47,  4000] loss: 0.542\n",
      "[47,  6000] loss: 0.584\n",
      "[47,  8000] loss: 0.572\n",
      "[47, 10000] loss: 0.586\n",
      "[47, 12000] loss: 0.615\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[47] loss: 1.900\n",
      "12499\n",
      "[48,  2000] loss: 0.505\n",
      "[48,  4000] loss: 0.580\n",
      "[48,  6000] loss: 0.595\n",
      "[48,  8000] loss: 0.578\n",
      "[48, 10000] loss: 0.593\n",
      "[48, 12000] loss: 0.630\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[48] loss: 1.813\n",
      "12499\n",
      "[49,  2000] loss: 0.508\n",
      "[49,  4000] loss: 0.564\n",
      "[49,  6000] loss: 0.544\n",
      "[49,  8000] loss: 0.573\n",
      "[49, 10000] loss: 0.598\n",
      "[49, 12000] loss: 0.605\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[49] loss: 1.784\n",
      "12499\n",
      "[50,  2000] loss: 0.508\n",
      "[50,  4000] loss: 0.547\n",
      "[50,  6000] loss: 0.568\n",
      "[50,  8000] loss: 0.603\n",
      "[50, 10000] loss: 0.636\n",
      "[50, 12000] loss: 0.612\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[50] loss: 1.832\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss\")\n",
    "visdom_accu = Visdom(env=\"testaccu\")\n",
    "visdom_test = Visdom(env=\"testloss\")\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu']),\n",
    "            name='test_accu',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss']),\n",
    "            name='test_loss',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 57 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)        #放进模型里\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()  #相同的累加\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class plane is: 54.3 %\n",
      "Accuracy for class car   is: 76.1 %\n",
      "Accuracy for class bird  is: 43.7 %\n",
      "Accuracy for class cat   is: 39.0 %\n",
      "Accuracy for class deer  is: 39.7 %\n",
      "Accuracy for class dog   is: 46.4 %\n",
      "Accuracy for class frog  is: 72.7 %\n",
      "Accuracy for class horse is: 61.3 %\n",
      "Accuracy for class ship  is: 76.7 %\n",
      "Accuracy for class truck is: 65.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}  #定义列表\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
