{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "电商18 180412126 王佳琦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.364\n",
      "[1,  4000] loss: 2.362\n",
      "[1,  6000] loss: 2.356\n",
      "[1,  8000] loss: 2.362\n",
      "[1, 10000] loss: 2.365\n",
      "[1, 12000] loss: 2.358\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[1] loss: 2.381\n",
      "12499\n",
      "[2,  2000] loss: 2.359\n",
      "[2,  4000] loss: 2.357\n",
      "[2,  6000] loss: 2.357\n",
      "[2,  8000] loss: 2.361\n",
      "[2, 10000] loss: 2.360\n",
      "[2, 12000] loss: 2.359\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[2] loss: 2.368\n",
      "12499\n",
      "[3,  2000] loss: 2.358\n",
      "[3,  4000] loss: 2.358\n",
      "[3,  6000] loss: 2.359\n",
      "[3,  8000] loss: 2.359\n",
      "[3, 10000] loss: 2.358\n",
      "[3, 12000] loss: 2.361\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[3] loss: 2.343\n",
      "12499\n",
      "[4,  2000] loss: 2.356\n",
      "[4,  4000] loss: 2.361\n",
      "[4,  6000] loss: 2.359\n",
      "[4,  8000] loss: 2.359\n",
      "[4, 10000] loss: 2.356\n",
      "[4, 12000] loss: 2.359\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[4] loss: 2.341\n",
      "12499\n",
      "[5,  2000] loss: 2.360\n",
      "[5,  4000] loss: 2.361\n",
      "[5,  6000] loss: 2.361\n",
      "[5,  8000] loss: 2.358\n",
      "[5, 10000] loss: 2.364\n",
      "[5, 12000] loss: 2.360\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[5] loss: 2.312\n",
      "12499\n",
      "[6,  2000] loss: 2.363\n",
      "[6,  4000] loss: 2.365\n",
      "[6,  6000] loss: 2.364\n",
      "[6,  8000] loss: 2.358\n",
      "[6, 10000] loss: 2.359\n",
      "[6, 12000] loss: 2.360\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[6] loss: 2.335\n",
      "12499\n",
      "[7,  2000] loss: 2.360\n",
      "[7,  4000] loss: 2.360\n",
      "[7,  6000] loss: 2.359\n",
      "[7,  8000] loss: 2.359\n",
      "[7, 10000] loss: 2.356\n",
      "[7, 12000] loss: 2.362\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[7] loss: 2.377\n",
      "12499\n",
      "[8,  2000] loss: 2.361\n",
      "[8,  4000] loss: 2.357\n",
      "[8,  6000] loss: 2.359\n",
      "[8,  8000] loss: 2.358\n",
      "[8, 10000] loss: 2.358\n",
      "[8, 12000] loss: 2.360\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[8] loss: 2.422\n",
      "12499\n",
      "[9,  2000] loss: 2.364\n",
      "[9,  4000] loss: 2.359\n",
      "[9,  6000] loss: 2.364\n",
      "[9,  8000] loss: 2.361\n",
      "[9, 10000] loss: 2.360\n",
      "[9, 12000] loss: 2.362\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[9] loss: 2.367\n",
      "12499\n",
      "[10,  2000] loss: 2.354\n",
      "[10,  4000] loss: 2.360\n",
      "[10,  6000] loss: 2.363\n",
      "[10,  8000] loss: 2.357\n",
      "[10, 10000] loss: 2.359\n",
      "[10, 12000] loss: 2.361\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[10] loss: 2.360\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.1\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.1\")\n",
    "visdom_test = Visdom(env=\"testloss_0.1\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.1',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.1']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.1']),\n",
    "            name='test_accu_0.1',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.1']),\n",
    "            name='test_loss_0.1',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.081\n",
      "[1,  4000] loss: 1.965\n",
      "[1,  6000] loss: 1.971\n",
      "[1,  8000] loss: 1.977\n",
      "[1, 10000] loss: 1.996\n",
      "[1, 12000] loss: 2.008\n",
      "Accuracy of the network on the 2500 test images: 27 %\n",
      "[1] loss: 1.919\n",
      "12499\n",
      "[2,  2000] loss: 1.983\n",
      "[2,  4000] loss: 2.005\n",
      "[2,  6000] loss: 1.984\n",
      "[2,  8000] loss: 2.010\n",
      "[2, 10000] loss: 2.048\n",
      "[2, 12000] loss: 2.024\n",
      "Accuracy of the network on the 2500 test images: 24 %\n",
      "[2] loss: 1.979\n",
      "12499\n",
      "[3,  2000] loss: 2.009\n",
      "[3,  4000] loss: 2.074\n",
      "[3,  6000] loss: 2.044\n",
      "[3,  8000] loss: 2.212\n",
      "[3, 10000] loss: 2.168\n",
      "[3, 12000] loss: 2.152\n",
      "Accuracy of the network on the 2500 test images: 18 %\n",
      "[3] loss: 2.072\n",
      "12499\n",
      "[4,  2000] loss: 2.093\n",
      "[4,  4000] loss: 2.059\n",
      "[4,  6000] loss: 2.112\n",
      "[4,  8000] loss: 2.131\n",
      "[4, 10000] loss: 2.199\n",
      "[4, 12000] loss: 2.118\n",
      "Accuracy of the network on the 2500 test images: 20 %\n",
      "[4] loss: 2.057\n",
      "12499\n",
      "[5,  2000] loss: 2.053\n",
      "[5,  4000] loss: 2.049\n",
      "[5,  6000] loss: 2.034\n",
      "[5,  8000] loss: 2.024\n",
      "[5, 10000] loss: 1.996\n",
      "[5, 12000] loss: 2.012\n",
      "Accuracy of the network on the 2500 test images: 23 %\n",
      "[5] loss: 2.059\n",
      "12499\n",
      "[6,  2000] loss: 2.023\n",
      "[6,  4000] loss: 2.007\n",
      "[6,  6000] loss: 2.034\n",
      "[6,  8000] loss: 2.019\n",
      "[6, 10000] loss: 2.033\n",
      "[6, 12000] loss: 2.014\n",
      "Accuracy of the network on the 2500 test images: 23 %\n",
      "[6] loss: 2.009\n",
      "12499\n",
      "[7,  2000] loss: 2.001\n",
      "[7,  4000] loss: 2.016\n",
      "[7,  6000] loss: 2.021\n",
      "[7,  8000] loss: 1.990\n",
      "[7, 10000] loss: 2.018\n",
      "[7, 12000] loss: 1.994\n",
      "Accuracy of the network on the 2500 test images: 23 %\n",
      "[7] loss: 1.991\n",
      "12499\n",
      "[8,  2000] loss: 2.035\n",
      "[8,  4000] loss: 2.016\n",
      "[8,  6000] loss: 2.029\n",
      "[8,  8000] loss: 2.029\n",
      "[8, 10000] loss: 2.021\n",
      "[8, 12000] loss: 2.020\n",
      "Accuracy of the network on the 2500 test images: 24 %\n",
      "[8] loss: 2.053\n",
      "12499\n",
      "[9,  2000] loss: 2.014\n",
      "[9,  4000] loss: 1.978\n",
      "[9,  6000] loss: 1.995\n",
      "[9,  8000] loss: 1.985\n",
      "[9, 10000] loss: 2.079\n",
      "[9, 12000] loss: 2.208\n",
      "Accuracy of the network on the 2500 test images: 16 %\n",
      "[9] loss: 2.162\n",
      "12499\n",
      "[10,  2000] loss: 2.092\n",
      "[10,  4000] loss: 2.014\n",
      "[10,  6000] loss: 2.031\n",
      "[10,  8000] loss: 2.000\n",
      "[10, 10000] loss: 2.013\n",
      "[10, 12000] loss: 1.982\n",
      "Accuracy of the network on the 2500 test images: 23 %\n",
      "[10] loss: 2.006\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.01\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.01\")\n",
    "visdom_test = Visdom(env=\"testloss_0.01\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.01',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.01']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.01']),\n",
    "            name='test_accu_0.01',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.01']),\n",
    "            name='test_loss_0.01',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.197\n",
      "[1,  4000] loss: 1.898\n",
      "[1,  6000] loss: 1.712\n",
      "[1,  8000] loss: 1.579\n",
      "[1, 10000] loss: 1.524\n",
      "[1, 12000] loss: 1.473\n",
      "Accuracy of the network on the 2500 test images: 44 %\n",
      "[1] loss: 1.514\n",
      "12499\n",
      "[2,  2000] loss: 1.403\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.327\n",
      "[2,  8000] loss: 1.337\n",
      "[2, 10000] loss: 1.313\n",
      "[2, 12000] loss: 1.283\n",
      "Accuracy of the network on the 2500 test images: 54 %\n",
      "[2] loss: 1.250\n",
      "12499\n",
      "[3,  2000] loss: 1.222\n",
      "[3,  4000] loss: 1.200\n",
      "[3,  6000] loss: 1.215\n",
      "[3,  8000] loss: 1.199\n",
      "[3, 10000] loss: 1.177\n",
      "[3, 12000] loss: 1.162\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[3] loss: 1.183\n",
      "12499\n",
      "[4,  2000] loss: 1.098\n",
      "[4,  4000] loss: 1.118\n",
      "[4,  6000] loss: 1.093\n",
      "[4,  8000] loss: 1.096\n",
      "[4, 10000] loss: 1.091\n",
      "[4, 12000] loss: 1.082\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[4] loss: 1.127\n",
      "12499\n",
      "[5,  2000] loss: 0.994\n",
      "[5,  4000] loss: 1.012\n",
      "[5,  6000] loss: 1.035\n",
      "[5,  8000] loss: 1.041\n",
      "[5, 10000] loss: 1.048\n",
      "[5, 12000] loss: 1.030\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[5] loss: 1.114\n",
      "12499\n",
      "[6,  2000] loss: 0.953\n",
      "[6,  4000] loss: 0.954\n",
      "[6,  6000] loss: 0.978\n",
      "[6,  8000] loss: 0.958\n",
      "[6, 10000] loss: 0.991\n",
      "[6, 12000] loss: 0.970\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[6] loss: 1.085\n",
      "12499\n",
      "[7,  2000] loss: 0.892\n",
      "[7,  4000] loss: 0.902\n",
      "[7,  6000] loss: 0.914\n",
      "[7,  8000] loss: 0.937\n",
      "[7, 10000] loss: 0.925\n",
      "[7, 12000] loss: 0.936\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[7] loss: 1.078\n",
      "12499\n",
      "[8,  2000] loss: 0.832\n",
      "[8,  4000] loss: 0.866\n",
      "[8,  6000] loss: 0.867\n",
      "[8,  8000] loss: 0.912\n",
      "[8, 10000] loss: 0.890\n",
      "[8, 12000] loss: 0.900\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[8] loss: 1.082\n",
      "12499\n",
      "[9,  2000] loss: 0.780\n",
      "[9,  4000] loss: 0.819\n",
      "[9,  6000] loss: 0.837\n",
      "[9,  8000] loss: 0.872\n",
      "[9, 10000] loss: 0.866\n",
      "[9, 12000] loss: 0.861\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[9] loss: 1.109\n",
      "12499\n",
      "[10,  2000] loss: 0.759\n",
      "[10,  4000] loss: 0.784\n",
      "[10,  6000] loss: 0.821\n",
      "[10,  8000] loss: 0.840\n",
      "[10, 10000] loss: 0.835\n",
      "[10, 12000] loss: 0.822\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[10] loss: 1.113\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.001\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.001\")\n",
    "visdom_test = Visdom(env=\"testloss_0.001\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.001',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.001']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.001']),\n",
    "            name='test_accu_0.001',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.001']),\n",
    "            name='test_loss_0.001',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用relu as 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.223\n",
      "[1,  4000] loss: 1.877\n",
      "[1,  6000] loss: 1.669\n",
      "[1,  8000] loss: 1.563\n",
      "[1, 10000] loss: 1.508\n",
      "[1, 12000] loss: 1.472\n",
      "Accuracy of the network on the 2500 test images: 48 %\n",
      "[1] loss: 1.398\n",
      "12499\n",
      "[2,  2000] loss: 1.382\n",
      "[2,  4000] loss: 1.355\n",
      "[2,  6000] loss: 1.349\n",
      "[2,  8000] loss: 1.322\n",
      "[2, 10000] loss: 1.304\n",
      "[2, 12000] loss: 1.296\n",
      "Accuracy of the network on the 2500 test images: 51 %\n",
      "[2] loss: 1.339\n",
      "12499\n",
      "[3,  2000] loss: 1.233\n",
      "[3,  4000] loss: 1.200\n",
      "[3,  6000] loss: 1.214\n",
      "[3,  8000] loss: 1.219\n",
      "[3, 10000] loss: 1.171\n",
      "[3, 12000] loss: 1.177\n",
      "Accuracy of the network on the 2500 test images: 55 %\n",
      "[3] loss: 1.298\n",
      "12499\n",
      "[4,  2000] loss: 1.123\n",
      "[4,  4000] loss: 1.127\n",
      "[4,  6000] loss: 1.127\n",
      "[4,  8000] loss: 1.120\n",
      "[4, 10000] loss: 1.129\n",
      "[4, 12000] loss: 1.105\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[4] loss: 1.120\n",
      "12499\n",
      "[5,  2000] loss: 1.021\n",
      "[5,  4000] loss: 1.040\n",
      "[5,  6000] loss: 1.049\n",
      "[5,  8000] loss: 1.075\n",
      "[5, 10000] loss: 1.064\n",
      "[5, 12000] loss: 1.049\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[5] loss: 1.141\n",
      "12499\n",
      "[6,  2000] loss: 0.998\n",
      "[6,  4000] loss: 0.989\n",
      "[6,  6000] loss: 1.010\n",
      "[6,  8000] loss: 1.004\n",
      "[6, 10000] loss: 0.974\n",
      "[6, 12000] loss: 1.030\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[6] loss: 1.106\n",
      "12499\n",
      "[7,  2000] loss: 0.921\n",
      "[7,  4000] loss: 0.955\n",
      "[7,  6000] loss: 0.967\n",
      "[7,  8000] loss: 0.949\n",
      "[7, 10000] loss: 0.982\n",
      "[7, 12000] loss: 0.986\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[7] loss: 1.109\n",
      "12499\n",
      "[8,  2000] loss: 0.889\n",
      "[8,  4000] loss: 0.890\n",
      "[8,  6000] loss: 0.915\n",
      "[8,  8000] loss: 0.935\n",
      "[8, 10000] loss: 0.949\n",
      "[8, 12000] loss: 0.943\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[8] loss: 1.154\n",
      "12499\n",
      "[9,  2000] loss: 0.824\n",
      "[9,  4000] loss: 0.883\n",
      "[9,  6000] loss: 0.885\n",
      "[9,  8000] loss: 0.902\n",
      "[9, 10000] loss: 0.928\n",
      "[9, 12000] loss: 0.918\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[9] loss: 1.092\n",
      "12499\n",
      "[10,  2000] loss: 0.812\n",
      "[10,  4000] loss: 0.836\n",
      "[10,  6000] loss: 0.846\n",
      "[10,  8000] loss: 0.873\n",
      "[10, 10000] loss: 0.859\n",
      "[10, 12000] loss: 0.902\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[10] loss: 1.144\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_relu\")\n",
    "visdom_accu = Visdom(env=\"testaccu_relu\")\n",
    "visdom_test = Visdom(env=\"testloss_relu\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_relu',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_relu']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_relu']),\n",
    "            name='test_accu_relu',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_relu']),\n",
    "            name='test_loss_relu',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sigmoid as 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.sigmoid(self.conv1(x)))\n",
    "        x = self.pool(F.sigmoid(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.315\n",
      "[1,  4000] loss: 2.314\n",
      "[1,  6000] loss: 2.313\n",
      "[1,  8000] loss: 2.312\n",
      "[1, 10000] loss: 2.310\n",
      "[1, 12000] loss: 2.310\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[1] loss: 2.309\n",
      "12499\n",
      "[2,  2000] loss: 2.310\n",
      "[2,  4000] loss: 2.310\n",
      "[2,  6000] loss: 2.309\n",
      "[2,  8000] loss: 2.309\n",
      "[2, 10000] loss: 2.307\n",
      "[2, 12000] loss: 2.307\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[2] loss: 2.311\n",
      "12499\n",
      "[3,  2000] loss: 2.307\n",
      "[3,  4000] loss: 2.307\n",
      "[3,  6000] loss: 2.307\n",
      "[3,  8000] loss: 2.306\n",
      "[3, 10000] loss: 2.306\n",
      "[3, 12000] loss: 2.305\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[3] loss: 2.305\n",
      "12499\n",
      "[4,  2000] loss: 2.305\n",
      "[4,  4000] loss: 2.305\n",
      "[4,  6000] loss: 2.305\n",
      "[4,  8000] loss: 2.305\n",
      "[4, 10000] loss: 2.305\n",
      "[4, 12000] loss: 2.304\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[4] loss: 2.303\n",
      "12499\n",
      "[5,  2000] loss: 2.304\n",
      "[5,  4000] loss: 2.305\n",
      "[5,  6000] loss: 2.305\n",
      "[5,  8000] loss: 2.304\n",
      "[5, 10000] loss: 2.303\n",
      "[5, 12000] loss: 2.304\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[5] loss: 2.304\n",
      "12499\n",
      "[6,  2000] loss: 2.304\n",
      "[6,  4000] loss: 2.303\n",
      "[6,  6000] loss: 2.304\n",
      "[6,  8000] loss: 2.304\n",
      "[6, 10000] loss: 2.304\n",
      "[6, 12000] loss: 2.304\n",
      "Accuracy of the network on the 2500 test images: 15 %\n",
      "[6] loss: 2.304\n",
      "12499\n",
      "[7,  2000] loss: 2.303\n",
      "[7,  4000] loss: 2.304\n",
      "[7,  6000] loss: 2.304\n",
      "[7,  8000] loss: 2.303\n",
      "[7, 10000] loss: 2.304\n",
      "[7, 12000] loss: 2.304\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[7] loss: 2.303\n",
      "12499\n",
      "[8,  2000] loss: 2.303\n",
      "[8,  4000] loss: 2.304\n",
      "[8,  6000] loss: 2.303\n",
      "[8,  8000] loss: 2.303\n",
      "[8, 10000] loss: 2.304\n",
      "[8, 12000] loss: 2.303\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[8] loss: 2.303\n",
      "12499\n",
      "[9,  2000] loss: 2.303\n",
      "[9,  4000] loss: 2.303\n",
      "[9,  6000] loss: 2.303\n",
      "[9,  8000] loss: 2.303\n",
      "[9, 10000] loss: 2.303\n",
      "[9, 12000] loss: 2.303\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[9] loss: 2.303\n",
      "12499\n",
      "[10,  2000] loss: 2.303\n",
      "[10,  4000] loss: 2.302\n",
      "[10,  6000] loss: 2.302\n",
      "[10,  8000] loss: 2.302\n",
      "[10, 10000] loss: 2.301\n",
      "[10, 12000] loss: 2.301\n",
      "Accuracy of the network on the 2500 test images: 15 %\n",
      "[10] loss: 2.300\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_sigmoid\")\n",
    "visdom_accu = Visdom(env=\"testaccu_sigmoid\")\n",
    "visdom_test = Visdom(env=\"testloss_sigmoid\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_sigmoid',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_sigmoid']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_sigmoid']),\n",
    "            name='test_accu_sigmoid',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_sigmoid']),\n",
    "            name='test_loss_sigmoid',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 tanh as 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.tanh(self.conv1(x)))\n",
    "        x = self.pool(F.tanh(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.973\n",
      "[1,  4000] loss: 1.672\n",
      "[1,  6000] loss: 1.572\n",
      "[1,  8000] loss: 1.519\n",
      "[1, 10000] loss: 1.486\n",
      "[1, 12000] loss: 1.418\n",
      "Accuracy of the network on the 2500 test images: 50 %\n",
      "[1] loss: 1.373\n",
      "12499\n",
      "[2,  2000] loss: 1.375\n",
      "[2,  4000] loss: 1.336\n",
      "[2,  6000] loss: 1.322\n",
      "[2,  8000] loss: 1.304\n",
      "[2, 10000] loss: 1.290\n",
      "[2, 12000] loss: 1.279\n",
      "Accuracy of the network on the 2500 test images: 53 %\n",
      "[2] loss: 1.329\n",
      "12499\n",
      "[3,  2000] loss: 1.208\n",
      "[3,  4000] loss: 1.235\n",
      "[3,  6000] loss: 1.194\n",
      "[3,  8000] loss: 1.203\n",
      "[3, 10000] loss: 1.196\n",
      "[3, 12000] loss: 1.180\n",
      "Accuracy of the network on the 2500 test images: 57 %\n",
      "[3] loss: 1.204\n",
      "12499\n",
      "[4,  2000] loss: 1.131\n",
      "[4,  4000] loss: 1.147\n",
      "[4,  6000] loss: 1.110\n",
      "[4,  8000] loss: 1.113\n",
      "[4, 10000] loss: 1.142\n",
      "[4, 12000] loss: 1.112\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[4] loss: 1.148\n",
      "12499\n",
      "[5,  2000] loss: 1.048\n",
      "[5,  4000] loss: 1.064\n",
      "[5,  6000] loss: 1.061\n",
      "[5,  8000] loss: 1.069\n",
      "[5, 10000] loss: 1.066\n",
      "[5, 12000] loss: 1.066\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[5] loss: 1.147\n",
      "12499\n",
      "[6,  2000] loss: 0.996\n",
      "[6,  4000] loss: 1.012\n",
      "[6,  6000] loss: 1.007\n",
      "[6,  8000] loss: 1.031\n",
      "[6, 10000] loss: 1.016\n",
      "[6, 12000] loss: 1.027\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[6] loss: 1.169\n",
      "12499\n",
      "[7,  2000] loss: 0.943\n",
      "[7,  4000] loss: 0.952\n",
      "[7,  6000] loss: 0.985\n",
      "[7,  8000] loss: 0.964\n",
      "[7, 10000] loss: 0.993\n",
      "[7, 12000] loss: 0.976\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[7] loss: 1.135\n",
      "12499\n",
      "[8,  2000] loss: 0.894\n",
      "[8,  4000] loss: 0.908\n",
      "[8,  6000] loss: 0.946\n",
      "[8,  8000] loss: 0.966\n",
      "[8, 10000] loss: 0.912\n",
      "[8, 12000] loss: 0.931\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[8] loss: 1.185\n",
      "12499\n",
      "[9,  2000] loss: 0.857\n",
      "[9,  4000] loss: 0.878\n",
      "[9,  6000] loss: 0.884\n",
      "[9,  8000] loss: 0.920\n",
      "[9, 10000] loss: 0.911\n",
      "[9, 12000] loss: 0.915\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[9] loss: 1.132\n",
      "12499\n",
      "[10,  2000] loss: 0.815\n",
      "[10,  4000] loss: 0.853\n",
      "[10,  6000] loss: 0.855\n",
      "[10,  8000] loss: 0.836\n",
      "[10, 10000] loss: 0.907\n",
      "[10, 12000] loss: 0.879\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[10] loss: 1.170\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_tanh\")\n",
    "visdom_accu = Visdom(env=\"testaccu_tanh\")\n",
    "visdom_test = Visdom(env=\"testloss_tanh\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_tanh',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_tanh']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_tanh']),\n",
    "            name='test_accu_tanh',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_tanh']),\n",
    "            name='test_loss_tanh',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "探索relu变种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.282\n",
      "[1,  4000] loss: 1.886\n",
      "[1,  6000] loss: 1.691\n",
      "[1,  8000] loss: 1.590\n",
      "[1, 10000] loss: 1.526\n",
      "[1, 12000] loss: 1.461\n",
      "Accuracy of the network on the 2500 test images: 48 %\n",
      "[1] loss: 1.412\n",
      "12499\n",
      "[2,  2000] loss: 1.406\n",
      "[2,  4000] loss: 1.364\n",
      "[2,  6000] loss: 1.332\n",
      "[2,  8000] loss: 1.325\n",
      "[2, 10000] loss: 1.299\n",
      "[2, 12000] loss: 1.272\n",
      "Accuracy of the network on the 2500 test images: 54 %\n",
      "[2] loss: 1.299\n",
      "12499\n",
      "[3,  2000] loss: 1.210\n",
      "[3,  4000] loss: 1.212\n",
      "[3,  6000] loss: 1.162\n",
      "[3,  8000] loss: 1.194\n",
      "[3, 10000] loss: 1.178\n",
      "[3, 12000] loss: 1.166\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[3] loss: 1.163\n",
      "12499\n",
      "[4,  2000] loss: 1.105\n",
      "[4,  4000] loss: 1.092\n",
      "[4,  6000] loss: 1.117\n",
      "[4,  8000] loss: 1.101\n",
      "[4, 10000] loss: 1.094\n",
      "[4, 12000] loss: 1.094\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[4] loss: 1.149\n",
      "12499\n",
      "[5,  2000] loss: 1.023\n",
      "[5,  4000] loss: 1.030\n",
      "[5,  6000] loss: 1.015\n",
      "[5,  8000] loss: 1.040\n",
      "[5, 10000] loss: 1.043\n",
      "[5, 12000] loss: 1.040\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[5] loss: 1.111\n",
      "12499\n",
      "[6,  2000] loss: 0.952\n",
      "[6,  4000] loss: 0.950\n",
      "[6,  6000] loss: 0.985\n",
      "[6,  8000] loss: 1.008\n",
      "[6, 10000] loss: 0.995\n",
      "[6, 12000] loss: 1.004\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[6] loss: 1.116\n",
      "12499\n",
      "[7,  2000] loss: 0.904\n",
      "[7,  4000] loss: 0.920\n",
      "[7,  6000] loss: 0.940\n",
      "[7,  8000] loss: 0.945\n",
      "[7, 10000] loss: 0.961\n",
      "[7, 12000] loss: 0.934\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[7] loss: 1.109\n",
      "12499\n",
      "[8,  2000] loss: 0.830\n",
      "[8,  4000] loss: 0.902\n",
      "[8,  6000] loss: 0.872\n",
      "[8,  8000] loss: 0.896\n",
      "[8, 10000] loss: 0.915\n",
      "[8, 12000] loss: 0.946\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[8] loss: 1.151\n",
      "12499\n",
      "[9,  2000] loss: 0.804\n",
      "[9,  4000] loss: 0.829\n",
      "[9,  6000] loss: 0.866\n",
      "[9,  8000] loss: 0.886\n",
      "[9, 10000] loss: 0.880\n",
      "[9, 12000] loss: 0.900\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[9] loss: 1.126\n",
      "12499\n",
      "[10,  2000] loss: 0.781\n",
      "[10,  4000] loss: 0.826\n",
      "[10,  6000] loss: 0.845\n",
      "[10,  8000] loss: 0.838\n",
      "[10, 10000] loss: 0.862\n",
      "[10, 12000] loss: 0.849\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[10] loss: 1.143\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_relu\")\n",
    "visdom_accu = Visdom(env=\"testaccu_relu\")\n",
    "visdom_test = Visdom(env=\"testloss_relu\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_relu',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_relu']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_relu']),\n",
    "            name='test_accu_relu',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_relu']),\n",
    "            name='test_loss_relu',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leakyrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.201\n",
      "[1,  4000] loss: 1.877\n",
      "[1,  6000] loss: 1.681\n",
      "[1,  8000] loss: 1.593\n",
      "[1, 10000] loss: 1.536\n",
      "[1, 12000] loss: 1.487\n",
      "Accuracy of the network on the 2500 test images: 47 %\n",
      "[1] loss: 1.443\n",
      "12499\n",
      "[2,  2000] loss: 1.421\n",
      "[2,  4000] loss: 1.384\n",
      "[2,  6000] loss: 1.363\n",
      "[2,  8000] loss: 1.334\n",
      "[2, 10000] loss: 1.314\n",
      "[2, 12000] loss: 1.288\n",
      "Accuracy of the network on the 2500 test images: 55 %\n",
      "[2] loss: 1.256\n",
      "12499\n",
      "[3,  2000] loss: 1.218\n",
      "[3,  4000] loss: 1.232\n",
      "[3,  6000] loss: 1.234\n",
      "[3,  8000] loss: 1.188\n",
      "[3, 10000] loss: 1.195\n",
      "[3, 12000] loss: 1.191\n",
      "Accuracy of the network on the 2500 test images: 59 %\n",
      "[3] loss: 1.165\n",
      "12499\n",
      "[4,  2000] loss: 1.094\n",
      "[4,  4000] loss: 1.126\n",
      "[4,  6000] loss: 1.122\n",
      "[4,  8000] loss: 1.128\n",
      "[4, 10000] loss: 1.126\n",
      "[4, 12000] loss: 1.086\n",
      "Accuracy of the network on the 2500 test images: 57 %\n",
      "[4] loss: 1.177\n",
      "12499\n",
      "[5,  2000] loss: 1.042\n",
      "[5,  4000] loss: 1.044\n",
      "[5,  6000] loss: 1.032\n",
      "[5,  8000] loss: 1.026\n",
      "[5, 10000] loss: 1.051\n",
      "[5, 12000] loss: 1.028\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[5] loss: 1.132\n",
      "12499\n",
      "[6,  2000] loss: 0.949\n",
      "[6,  4000] loss: 0.969\n",
      "[6,  6000] loss: 0.994\n",
      "[6,  8000] loss: 0.985\n",
      "[6, 10000] loss: 1.009\n",
      "[6, 12000] loss: 1.002\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[6] loss: 1.095\n",
      "12499\n",
      "[7,  2000] loss: 0.924\n",
      "[7,  4000] loss: 0.952\n",
      "[7,  6000] loss: 0.937\n",
      "[7,  8000] loss: 0.909\n",
      "[7, 10000] loss: 0.949\n",
      "[7, 12000] loss: 0.952\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[7] loss: 1.080\n",
      "12499\n",
      "[8,  2000] loss: 0.854\n",
      "[8,  4000] loss: 0.882\n",
      "[8,  6000] loss: 0.882\n",
      "[8,  8000] loss: 0.908\n",
      "[8, 10000] loss: 0.917\n",
      "[8, 12000] loss: 0.935\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[8] loss: 1.114\n",
      "12499\n",
      "[9,  2000] loss: 0.817\n",
      "[9,  4000] loss: 0.845\n",
      "[9,  6000] loss: 0.844\n",
      "[9,  8000] loss: 0.910\n",
      "[9, 10000] loss: 0.880\n",
      "[9, 12000] loss: 0.887\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[9] loss: 1.123\n",
      "12499\n",
      "[10,  2000] loss: 0.784\n",
      "[10,  4000] loss: 0.812\n",
      "[10,  6000] loss: 0.831\n",
      "[10,  8000] loss: 0.825\n",
      "[10, 10000] loss: 0.861\n",
      "[10, 12000] loss: 0.874\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[10] loss: 1.105\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_leakyrelu\")\n",
    "visdom_accu = Visdom(env=\"testaccu_leakyrelu\")\n",
    "visdom_test = Visdom(env=\"testloss_leakyrelu\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_leakyrelu',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_leakyrelu']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_leakyrelu']),\n",
    "            name='test_accu_leakyrelu',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_leakyrelu']),\n",
    "            name='test_loss_leakyrelu',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.rrelu(self.conv1(x)))\n",
    "        x = self.pool(F.rrelu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.rrelu(self.fc1(x))\n",
    "        x = F.rrelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.181\n",
      "[1,  4000] loss: 1.792\n",
      "[1,  6000] loss: 1.583\n",
      "[1,  8000] loss: 1.516\n",
      "[1, 10000] loss: 1.444\n",
      "[1, 12000] loss: 1.418\n",
      "Accuracy of the network on the 2500 test images: 47 %\n",
      "[1] loss: 1.433\n",
      "12499\n",
      "[2,  2000] loss: 1.329\n",
      "[2,  4000] loss: 1.312\n",
      "[2,  6000] loss: 1.289\n",
      "[2,  8000] loss: 1.265\n",
      "[2, 10000] loss: 1.222\n",
      "[2, 12000] loss: 1.241\n",
      "Accuracy of the network on the 2500 test images: 57 %\n",
      "[2] loss: 1.210\n",
      "12499\n",
      "[3,  2000] loss: 1.161\n",
      "[3,  4000] loss: 1.167\n",
      "[3,  6000] loss: 1.156\n",
      "[3,  8000] loss: 1.133\n",
      "[3, 10000] loss: 1.139\n",
      "[3, 12000] loss: 1.131\n",
      "Accuracy of the network on the 2500 test images: 58 %\n",
      "[3] loss: 1.171\n",
      "12499\n",
      "[4,  2000] loss: 1.067\n",
      "[4,  4000] loss: 1.064\n",
      "[4,  6000] loss: 1.074\n",
      "[4,  8000] loss: 1.066\n",
      "[4, 10000] loss: 1.058\n",
      "[4, 12000] loss: 1.058\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[4] loss: 1.105\n",
      "12499\n",
      "[5,  2000] loss: 0.991\n",
      "[5,  4000] loss: 1.013\n",
      "[5,  6000] loss: 0.980\n",
      "[5,  8000] loss: 0.995\n",
      "[5, 10000] loss: 1.036\n",
      "[5, 12000] loss: 0.990\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[5] loss: 1.064\n",
      "12499\n",
      "[6,  2000] loss: 0.917\n",
      "[6,  4000] loss: 0.947\n",
      "[6,  6000] loss: 0.961\n",
      "[6,  8000] loss: 0.966\n",
      "[6, 10000] loss: 0.973\n",
      "[6, 12000] loss: 0.959\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[6] loss: 1.083\n",
      "12499\n",
      "[7,  2000] loss: 0.882\n",
      "[7,  4000] loss: 0.916\n",
      "[7,  6000] loss: 0.910\n",
      "[7,  8000] loss: 0.912\n",
      "[7, 10000] loss: 0.919\n",
      "[7, 12000] loss: 0.946\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[7] loss: 1.061\n",
      "12499\n",
      "[8,  2000] loss: 0.839\n",
      "[8,  4000] loss: 0.867\n",
      "[8,  6000] loss: 0.898\n",
      "[8,  8000] loss: 0.890\n",
      "[8, 10000] loss: 0.885\n",
      "[8, 12000] loss: 0.890\n",
      "Accuracy of the network on the 2500 test images: 64 %\n",
      "[8] loss: 1.060\n",
      "12499\n",
      "[9,  2000] loss: 0.831\n",
      "[9,  4000] loss: 0.834\n",
      "[9,  6000] loss: 0.839\n",
      "[9,  8000] loss: 0.862\n",
      "[9, 10000] loss: 0.861\n",
      "[9, 12000] loss: 0.868\n",
      "Accuracy of the network on the 2500 test images: 64 %\n",
      "[9] loss: 1.040\n",
      "12499\n",
      "[10,  2000] loss: 0.765\n",
      "[10,  4000] loss: 0.816\n",
      "[10,  6000] loss: 0.827\n",
      "[10,  8000] loss: 0.843\n",
      "[10, 10000] loss: 0.855\n",
      "[10, 12000] loss: 0.831\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[10] loss: 1.093\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_rrelu\")\n",
    "visdom_accu = Visdom(env=\"testaccu_rrelu\")\n",
    "visdom_test = Visdom(env=\"testloss_rrelu\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_rrelu',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_rrelu']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_rrelu']),\n",
    "            name='test_accu_rrelu',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_rrelu']),\n",
    "            name='test_loss_rrelu',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.rrelu(self.conv1(x)))\n",
    "        x = self.pool(F.rrelu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.rrelu(self.fc1(x))\n",
    "        x = F.rrelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.203\n",
      "[1,  4000] loss: 1.861\n",
      "[1,  6000] loss: 1.689\n",
      "[1,  8000] loss: 1.580\n",
      "[1, 10000] loss: 1.512\n",
      "[1, 12000] loss: 1.452\n",
      "Accuracy of the network on the 2500 test images: 47 %\n",
      "[1] loss: 1.478\n",
      "12499\n",
      "[2,  2000] loss: 1.374\n",
      "[2,  4000] loss: 1.344\n",
      "[2,  6000] loss: 1.317\n",
      "[2,  8000] loss: 1.285\n",
      "[2, 10000] loss: 1.255\n",
      "[2, 12000] loss: 1.250\n",
      "Accuracy of the network on the 2500 test images: 57 %\n",
      "[2] loss: 1.223\n",
      "12499\n",
      "[3,  2000] loss: 1.164\n",
      "[3,  4000] loss: 1.165\n",
      "[3,  6000] loss: 1.162\n",
      "[3,  8000] loss: 1.151\n",
      "[3, 10000] loss: 1.136\n",
      "[3, 12000] loss: 1.121\n",
      "Accuracy of the network on the 2500 test images: 60 %\n",
      "[3] loss: 1.125\n",
      "12499\n",
      "[4,  2000] loss: 1.042\n",
      "[4,  4000] loss: 1.050\n",
      "[4,  6000] loss: 1.052\n",
      "[4,  8000] loss: 1.053\n",
      "[4, 10000] loss: 1.042\n",
      "[4, 12000] loss: 1.055\n",
      "Accuracy of the network on the 2500 test images: 63 %\n",
      "[4] loss: 1.067\n",
      "12499\n",
      "[5,  2000] loss: 0.969\n",
      "[5,  4000] loss: 0.967\n",
      "[5,  6000] loss: 1.010\n",
      "[5,  8000] loss: 0.985\n",
      "[5, 10000] loss: 0.976\n",
      "[5, 12000] loss: 0.967\n",
      "Accuracy of the network on the 2500 test images: 61 %\n",
      "[5] loss: 1.122\n",
      "12499\n",
      "[6,  2000] loss: 0.922\n",
      "[6,  4000] loss: 0.908\n",
      "[6,  6000] loss: 0.912\n",
      "[6,  8000] loss: 0.920\n",
      "[6, 10000] loss: 0.940\n",
      "[6, 12000] loss: 0.945\n",
      "Accuracy of the network on the 2500 test images: 62 %\n",
      "[6] loss: 1.055\n",
      "12499\n",
      "[7,  2000] loss: 0.853\n",
      "[7,  4000] loss: 0.891\n",
      "[7,  6000] loss: 0.894\n",
      "[7,  8000] loss: 0.878\n",
      "[7, 10000] loss: 0.902\n",
      "[7, 12000] loss: 0.892\n",
      "Accuracy of the network on the 2500 test images: 64 %\n",
      "[7] loss: 1.037\n",
      "12499\n",
      "[8,  2000] loss: 0.824\n",
      "[8,  4000] loss: 0.839\n",
      "[8,  6000] loss: 0.852\n",
      "[8,  8000] loss: 0.850\n",
      "[8, 10000] loss: 0.865\n",
      "[8, 12000] loss: 0.857\n",
      "Accuracy of the network on the 2500 test images: 65 %\n",
      "[8] loss: 1.041\n",
      "12499\n",
      "[9,  2000] loss: 0.792\n",
      "[9,  4000] loss: 0.798\n",
      "[9,  6000] loss: 0.820\n",
      "[9,  8000] loss: 0.851\n",
      "[9, 10000] loss: 0.832\n",
      "[9, 12000] loss: 0.830\n",
      "Accuracy of the network on the 2500 test images: 65 %\n",
      "[9] loss: 1.018\n",
      "12499\n",
      "[10,  2000] loss: 0.757\n",
      "[10,  4000] loss: 0.762\n",
      "[10,  6000] loss: 0.802\n",
      "[10,  8000] loss: 0.807\n",
      "[10, 10000] loss: 0.819\n",
      "[10, 12000] loss: 0.807\n",
      "Accuracy of the network on the 2500 test images: 64 %\n",
      "[10] loss: 1.042\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.001\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.001\")\n",
    "visdom_test = Visdom(env=\"testloss_0.001\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.001',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.001']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.001']),\n",
    "            name='test_accu_0.001',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.001']),\n",
    "            name='test_loss_0.001',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.rrelu(self.conv1(x)))\n",
    "        x = self.pool(F.rrelu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.rrelu(self.fc1(x))\n",
    "        x = F.rrelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.298\n",
      "[1,  6000] loss: 2.289\n",
      "[1,  8000] loss: 2.255\n",
      "[1, 10000] loss: 2.186\n",
      "[1, 12000] loss: 2.096\n",
      "Accuracy of the network on the 2500 test images: 26 %\n",
      "[1] loss: 2.063\n",
      "12499\n",
      "[2,  2000] loss: 2.052\n",
      "[2,  4000] loss: 1.982\n",
      "[2,  6000] loss: 1.932\n",
      "[2,  8000] loss: 1.903\n",
      "[2, 10000] loss: 1.867\n",
      "[2, 12000] loss: 1.819\n",
      "Accuracy of the network on the 2500 test images: 37 %\n",
      "[2] loss: 1.777\n",
      "12499\n",
      "[3,  2000] loss: 1.785\n",
      "[3,  4000] loss: 1.744\n",
      "[3,  6000] loss: 1.696\n",
      "[3,  8000] loss: 1.686\n",
      "[3, 10000] loss: 1.662\n",
      "[3, 12000] loss: 1.637\n",
      "Accuracy of the network on the 2500 test images: 39 %\n",
      "[3] loss: 1.679\n",
      "12499\n",
      "[4,  2000] loss: 1.592\n",
      "[4,  4000] loss: 1.571\n",
      "[4,  6000] loss: 1.560\n",
      "[4,  8000] loss: 1.534\n",
      "[4, 10000] loss: 1.511\n",
      "[4, 12000] loss: 1.517\n",
      "Accuracy of the network on the 2500 test images: 44 %\n",
      "[4] loss: 1.523\n",
      "12499\n",
      "[5,  2000] loss: 1.475\n",
      "[5,  4000] loss: 1.451\n",
      "[5,  6000] loss: 1.453\n",
      "[5,  8000] loss: 1.452\n",
      "[5, 10000] loss: 1.435\n",
      "[5, 12000] loss: 1.428\n",
      "Accuracy of the network on the 2500 test images: 48 %\n",
      "[5] loss: 1.435\n",
      "12499\n",
      "[6,  2000] loss: 1.410\n",
      "[6,  4000] loss: 1.390\n",
      "[6,  6000] loss: 1.361\n",
      "[6,  8000] loss: 1.384\n",
      "[6, 10000] loss: 1.362\n",
      "[6, 12000] loss: 1.365\n",
      "Accuracy of the network on the 2500 test images: 50 %\n",
      "[6] loss: 1.367\n",
      "12499\n",
      "[7,  2000] loss: 1.342\n",
      "[7,  4000] loss: 1.343\n",
      "[7,  6000] loss: 1.305\n",
      "[7,  8000] loss: 1.319\n",
      "[7, 10000] loss: 1.314\n",
      "[7, 12000] loss: 1.315\n",
      "Accuracy of the network on the 2500 test images: 52 %\n",
      "[7] loss: 1.328\n",
      "12499\n",
      "[8,  2000] loss: 1.289\n",
      "[8,  4000] loss: 1.307\n",
      "[8,  6000] loss: 1.263\n",
      "[8,  8000] loss: 1.289\n",
      "[8, 10000] loss: 1.254\n",
      "[8, 12000] loss: 1.248\n",
      "Accuracy of the network on the 2500 test images: 53 %\n",
      "[8] loss: 1.291\n",
      "12499\n",
      "[9,  2000] loss: 1.238\n",
      "[9,  4000] loss: 1.223\n",
      "[9,  6000] loss: 1.221\n",
      "[9,  8000] loss: 1.243\n",
      "[9, 10000] loss: 1.213\n",
      "[9, 12000] loss: 1.226\n",
      "Accuracy of the network on the 2500 test images: 56 %\n",
      "[9] loss: 1.231\n",
      "12499\n",
      "[10,  2000] loss: 1.216\n",
      "[10,  4000] loss: 1.188\n",
      "[10,  6000] loss: 1.188\n",
      "[10,  8000] loss: 1.187\n",
      "[10, 10000] loss: 1.156\n",
      "[10, 12000] loss: 1.183\n",
      "Accuracy of the network on the 2500 test images: 56 %\n",
      "[10] loss: 1.241\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.0001\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.0001\")\n",
    "visdom_test = Visdom(env=\"testloss_0.0001\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.0001',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.0001']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.0001']),\n",
    "            name='test_accu_0.0001',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.0001']),\n",
    "            name='test_loss_0.0001',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#数据集加载时，默认的图片格式是 numpy，所以通过 transforms 转换成 Tensor。\n",
    "                                                              #然后，再对输入图片进行标准化。\n",
    "    #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差，Normalize对每个通道执行以下操作：image =（图像-平均值）/ std\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "#batchsize: 批大小 num_works:num_works: 是否多进程读取数据 shuffle: 每个 epoch 是否乱序 drop_last: 当样本数不能被 batchsize 整除时，是否舍弃最后一批数据\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img*0.5 + 0.5     # unnormalize  还原被归一化的数据\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    #在pytorch中张量tensor对图象的存储是(b,c,w,h)分别表示(图片数量，通道数，图片高，图片宽)。\n",
    "\n",
    "                                                    #单独说tensor中的某张图片，也就是(管道数，宽，高)。而标准的rbg图象是(宽，高，管道数)。\n",
    "    plt.show()\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             #定义卷积层和池化层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)       #定义全连接层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.rrelu(self.conv1(x)))\n",
    "        x = self.pool(F.rrelu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.rrelu(self.fc1(x))\n",
    "        x = F.rrelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()         #用交叉熵作loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)  #随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302\n",
      "[1,  4000] loss: 2.303\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.301\n",
      "[1, 10000] loss: 2.301\n",
      "[1, 12000] loss: 2.300\n",
      "Accuracy of the network on the 2500 test images: 10 %\n",
      "[1] loss: 2.299\n",
      "12499\n",
      "[2,  2000] loss: 2.299\n",
      "[2,  4000] loss: 2.298\n",
      "[2,  6000] loss: 2.298\n",
      "[2,  8000] loss: 2.296\n",
      "[2, 10000] loss: 2.295\n",
      "[2, 12000] loss: 2.293\n",
      "Accuracy of the network on the 2500 test images: 16 %\n",
      "[2] loss: 2.293\n",
      "12499\n",
      "[3,  2000] loss: 2.292\n",
      "[3,  4000] loss: 2.291\n",
      "[3,  6000] loss: 2.288\n",
      "[3,  8000] loss: 2.287\n",
      "[3, 10000] loss: 2.283\n",
      "[3, 12000] loss: 2.281\n",
      "Accuracy of the network on the 2500 test images: 20 %\n",
      "[3] loss: 2.278\n",
      "12499\n",
      "[4,  2000] loss: 2.277\n",
      "[4,  4000] loss: 2.272\n",
      "[4,  6000] loss: 2.267\n",
      "[4,  8000] loss: 2.262\n",
      "[4, 10000] loss: 2.256\n",
      "[4, 12000] loss: 2.248\n",
      "Accuracy of the network on the 2500 test images: 20 %\n",
      "[4] loss: 2.240\n",
      "12499\n",
      "[5,  2000] loss: 2.234\n",
      "[5,  4000] loss: 2.226\n",
      "[5,  6000] loss: 2.211\n",
      "[5,  8000] loss: 2.197\n",
      "[5, 10000] loss: 2.181\n",
      "[5, 12000] loss: 2.170\n",
      "Accuracy of the network on the 2500 test images: 22 %\n",
      "[5] loss: 2.156\n",
      "12499\n",
      "[6,  2000] loss: 2.147\n",
      "[6,  4000] loss: 2.140\n",
      "[6,  6000] loss: 2.126\n",
      "[6,  8000] loss: 2.115\n",
      "[6, 10000] loss: 2.117\n",
      "[6, 12000] loss: 2.097\n",
      "Accuracy of the network on the 2500 test images: 25 %\n",
      "[6] loss: 2.089\n",
      "12499\n",
      "[7,  2000] loss: 2.095\n",
      "[7,  4000] loss: 2.072\n",
      "[7,  6000] loss: 2.067\n",
      "[7,  8000] loss: 2.066\n",
      "[7, 10000] loss: 2.045\n",
      "[7, 12000] loss: 2.046\n",
      "Accuracy of the network on the 2500 test images: 27 %\n",
      "[7] loss: 2.037\n",
      "12499\n",
      "[8,  2000] loss: 2.028\n",
      "[8,  4000] loss: 2.026\n",
      "[8,  6000] loss: 2.030\n",
      "[8,  8000] loss: 1.993\n",
      "[8, 10000] loss: 2.003\n",
      "[8, 12000] loss: 1.994\n",
      "Accuracy of the network on the 2500 test images: 29 %\n",
      "[8] loss: 1.985\n",
      "12499\n",
      "[9,  2000] loss: 1.978\n",
      "[9,  4000] loss: 1.970\n",
      "[9,  6000] loss: 1.969\n",
      "[9,  8000] loss: 1.965\n",
      "[9, 10000] loss: 1.971\n",
      "[9, 12000] loss: 1.934\n",
      "Accuracy of the network on the 2500 test images: 30 %\n",
      "[9] loss: 1.941\n",
      "12499\n",
      "[10,  2000] loss: 1.947\n",
      "[10,  4000] loss: 1.928\n",
      "[10,  6000] loss: 1.936\n",
      "[10,  8000] loss: 1.926\n",
      "[10, 10000] loss: 1.924\n",
      "[10, 12000] loss: 1.918\n",
      "Accuracy of the network on the 2500 test images: 31 %\n",
      "[10] loss: 1.911\n",
      "12499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "visdom_show = Visdom(env=\"trainloss_0.00001\")\n",
    "visdom_accu = Visdom(env=\"testaccu_0.00001\")\n",
    "visdom_test = Visdom(env=\"testloss_0.00001\")\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "        #可视化\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data          \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()       #梯度从零开始\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            if (i+1)==12000:\n",
    "                visdom_show.line(\n",
    "                    X=[epoch+1],\n",
    "                    Y=[float(running_loss / 2000)],\n",
    "                    win='accu and loss',\n",
    "                    name='train_loss_0.00001',\n",
    "                    opts=dict(title='accu and loss',  legend=['train_loss_0.00001']),\n",
    "                    update='append')\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss2=0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)        #放进模型里\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  #相同的累加\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss2 += loss.item()\n",
    "        print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "        visdom_accu.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[(correct / total)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_accu_0.00001']),\n",
    "            name='test_accu_0.00001',\n",
    "            update='append')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1,running_loss2 / 2500))\n",
    "        visdom_test.line(\n",
    "            X=[epoch+1],\n",
    "            Y=[float(running_loss2 / 2500)],\n",
    "            win='accu and loss',\n",
    "            opts=dict(title='accu and loss',  legend=['test_loss_0.00001']),\n",
    "            name='test_loss_0.00001',\n",
    "            update='append')\n",
    "        print(i)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
